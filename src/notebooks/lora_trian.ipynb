{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14482540,"sourceType":"datasetVersion","datasetId":9250146}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -U \\\n  bitsandbytes \\\n  transformers \\\n  peft \\\n  accelerate \\\n  datasets\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-15T08:59:10.554248Z","iopub.execute_input":"2026-01-15T08:59:10.554550Z","iopub.status.idle":"2026-01-15T08:59:30.869515Z","shell.execute_reply.started":"2026-01-15T08:59:10.554526Z","shell.execute_reply":"2026-01-15T08:59:30.868631Z"}},"outputs":[{"name":"stdout","text":"Collecting bitsandbytes\n  Downloading bitsandbytes-0.49.1-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\nRequirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\nCollecting transformers\n  Downloading transformers-4.57.5-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (0.17.1)\nCollecting peft\n  Downloading peft-0.18.1-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.11.0)\nCollecting accelerate\n  Downloading accelerate-1.12.0-py3-none-any.whl.metadata (19 kB)\nRequirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.4.1)\nCollecting datasets\n  Downloading datasets-4.5.0-py3-none-any.whl.metadata (19 kB)\nRequirement already satisfied: torch<3,>=2.3 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.8.0+cu126)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.0.2)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (25.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\nRequirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.5)\nRequirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from peft) (5.9.5)\nRequirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (22.0.0)\nRequirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.4.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\nRequirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.28.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\nRequirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.18)\nRequirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.10.0)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\nRequirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (4.12.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (2025.11.12)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\nRequirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (3.11)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.1rc0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.6.2)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (75.2.0)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.80)\nRequirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (9.10.2.21)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.3.0.4)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (10.3.7.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.7.1.2)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.5.4.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (0.7.1)\nRequirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (2.27.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.85)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.11.1.6)\nRequirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.4.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.3)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3,>=2.3->bitsandbytes) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3,>=2.3->bitsandbytes) (3.0.3)\nDownloading bitsandbytes-0.49.1-py3-none-manylinux_2_24_x86_64.whl (59.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading transformers-4.57.5-py3-none-any.whl (12.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m109.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading peft-0.18.1-py3-none-any.whl (556 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.0/557.0 kB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading accelerate-1.12.0-py3-none-any.whl (380 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.9/380.9 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading datasets-4.5.0-py3-none-any.whl (515 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m515.2/515.2 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: transformers, datasets, bitsandbytes, accelerate, peft\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.57.1\n    Uninstalling transformers-4.57.1:\n      Successfully uninstalled transformers-4.57.1\n  Attempting uninstall: datasets\n    Found existing installation: datasets 4.4.1\n    Uninstalling datasets-4.4.1:\n      Successfully uninstalled datasets-4.4.1\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 1.11.0\n    Uninstalling accelerate-1.11.0:\n      Successfully uninstalled accelerate-1.11.0\n  Attempting uninstall: peft\n    Found existing installation: peft 0.17.1\n    Uninstalling peft-0.17.1:\n      Successfully uninstalled peft-0.17.1\nSuccessfully installed accelerate-1.12.0 bitsandbytes-0.49.1 datasets-4.5.0 peft-0.18.1 transformers-4.57.5\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport torch\nfrom datasets import load_dataset\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForCausalLM,\n    BitsAndBytesConfig,\n    TrainingArguments,\n    Trainer,\n    DataCollatorForLanguageModeling,\n)\nfrom peft import (\n    LoraConfig,\n    get_peft_model,\n    prepare_model_for_kbit_training,\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T08:59:30.871377Z","iopub.execute_input":"2026-01-15T08:59:30.871636Z","iopub.status.idle":"2026-01-15T09:00:01.064315Z","shell.execute_reply.started":"2026-01-15T08:59:30.871609Z","shell.execute_reply":"2026-01-15T09:00:01.063519Z"}},"outputs":[{"name":"stderr","text":"2026-01-15 08:59:45.746546: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1768467585.968373      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1768467586.034310      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1768467586.596174      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768467586.596212      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768467586.596216      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768467586.596218      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"MODEL_NAME = \"Qwen/Qwen2.5-1.5B-Instruct\"\n\nDATA_DIR = \"/kaggle/input/instruct-dataset\"\nTRAIN_FILE = os.path.join(DATA_DIR, \"train.jsonl\")\nVAL_FILE = os.path.join(DATA_DIR, \"val.jsonl\")\n\nADAPTER_DIR = \"./adapters\"\n\nMAX_SEQ_LEN = 512","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T09:00:01.065270Z","iopub.execute_input":"2026-01-15T09:00:01.065908Z","iopub.status.idle":"2026-01-15T09:00:01.070015Z","shell.execute_reply.started":"2026-01-15T09:00:01.065880Z","shell.execute_reply":"2026-01-15T09:00:01.069323Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\n    MODEL_NAME,\n    trust_remote_code=True\n)\n\nif tokenizer.pad_token is None:\n    tokenizer.pad_token = tokenizer.eos_token\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T09:00:01.071097Z","iopub.execute_input":"2026-01-15T09:00:01.071460Z","iopub.status.idle":"2026-01-15T09:00:03.362908Z","shell.execute_reply.started":"2026-01-15T09:00:01.071425Z","shell.execute_reply":"2026-01-15T09:00:03.362331Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"154179637b63462b9c8209654d3d8145"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"313615168e63419aa46d0388ca7eff7a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4b62096196b4d1c88526498aff73de0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba1a23bbe33642da87cef2ebcec4c903"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"dataset = load_dataset(\n    \"json\",\n    data_files={\n        \"train\": TRAIN_FILE,\n        \"validation\": VAL_FILE,\n    }\n)\n\nprint(dataset)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T09:00:03.363718Z","iopub.execute_input":"2026-01-15T09:00:03.363923Z","iopub.status.idle":"2026-01-15T09:00:03.673457Z","shell.execute_reply.started":"2026-01-15T09:00:03.363902Z","shell.execute_reply":"2026-01-15T09:00:03.672884Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0e5048386a740cdbe39283e7b4541ed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8694810855324d2c9265d576ff0cfa63"}},"metadata":{}},{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['instruction', 'input', 'output'],\n        num_rows: 885\n    })\n    validation: Dataset({\n        features: ['instruction', 'input', 'output'],\n        num_rows: 99\n    })\n})\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"def format_prompt(example):\n    return (\n        \"### Instruction:\\n\"\n        f\"{example['instruction']}\\n\\n\"\n        \"### Input:\\n\"\n        f\"{example['input']}\\n\\n\"\n        \"### Response:\\n\"\n        f\"{example['output']}\"\n    )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T09:00:03.674337Z","iopub.execute_input":"2026-01-15T09:00:03.674612Z","iopub.status.idle":"2026-01-15T09:00:03.678452Z","shell.execute_reply.started":"2026-01-15T09:00:03.674585Z","shell.execute_reply":"2026-01-15T09:00:03.677811Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def tokenize_fn(example):\n    text = format_prompt(example)\n    tokens = tokenizer(\n        text,\n        truncation=True,\n        max_length=MAX_SEQ_LEN,\n        padding=False,\n    )\n    tokens[\"labels\"] = tokens[\"input_ids\"].copy()\n    return tokens\n\ntokenized_ds = dataset.map(\n    tokenize_fn,\n    remove_columns=dataset[\"train\"].column_names,\n    batched=False,\n)\n\nprint(tokenized_ds)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T09:00:03.680335Z","iopub.execute_input":"2026-01-15T09:00:03.680867Z","iopub.status.idle":"2026-01-15T09:00:05.194162Z","shell.execute_reply.started":"2026-01-15T09:00:03.680843Z","shell.execute_reply":"2026-01-15T09:00:05.193313Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/885 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c688febd613a4547963fbc5ba84f5aa3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/99 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"519d1dd4d0b84915960592848a7168f3"}},"metadata":{}},{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['input_ids', 'attention_mask', 'labels'],\n        num_rows: 885\n    })\n    validation: Dataset({\n        features: ['input_ids', 'attention_mask', 'labels'],\n        num_rows: 99\n    })\n})\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"bnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.float16,\n    bnb_4bit_use_double_quant=False,\n)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    MODEL_NAME,\n    quantization_config=bnb_config,\n    device_map=\"auto\",\n    trust_remote_code=True,\n)\n\nmodel = prepare_model_for_kbit_training(model)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T09:00:05.194886Z","iopub.execute_input":"2026-01-15T09:00:05.195117Z","iopub.status.idle":"2026-01-15T09:00:25.668793Z","shell.execute_reply.started":"2026-01-15T09:00:05.195093Z","shell.execute_reply":"2026-01-15T09:00:25.668188Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/660 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"669920d02c7d4f8ab595389e620bd24e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/3.09G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d988b79f3f94e7b9e9b29e7c8585eb5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/242 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9e6c2fdf47c444dac3fe955a90bb421"}},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"lora_config = LoraConfig(\n    r=16,\n    lora_alpha=32,\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n    target_modules=[\n        \"q_proj\",\n        \"v_proj\",\n    ],\n)\n\n\nmodel = get_peft_model(model, lora_config)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T09:00:25.669642Z","iopub.execute_input":"2026-01-15T09:00:25.670359Z","iopub.status.idle":"2026-01-15T09:00:25.756264Z","shell.execute_reply.started":"2026-01-15T09:00:25.670330Z","shell.execute_reply":"2026-01-15T09:00:25.755724Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def print_trainable_params(model):\n    trainable = 0\n    total = 0\n    for _, param in model.named_parameters():\n        total += param.numel()\n        if param.requires_grad:\n            trainable += param.numel()\n    print(f\"Trainable params: {trainable}\")\n    print(f\"Total params: {total}\")\n    print(f\"Trainable %: {100 * trainable / total:.2f}%\")\n\nprint_trainable_params(model)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T09:00:25.757058Z","iopub.execute_input":"2026-01-15T09:00:25.757958Z","iopub.status.idle":"2026-01-15T09:00:27.669347Z","shell.execute_reply.started":"2026-01-15T09:00:25.757921Z","shell.execute_reply":"2026-01-15T09:00:27.668353Z"}},"outputs":[{"name":"stdout","text":"Trainable params: 2179072\nTotal params: 890795520\nTrainable %: 0.24%\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"!pip install -U transformers accelerate peft","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T09:00:27.670442Z","iopub.execute_input":"2026-01-15T09:00:27.670768Z","iopub.status.idle":"2026-01-15T09:00:36.492365Z","shell.execute_reply.started":"2026-01-15T09:00:27.670735Z","shell.execute_reply":"2026-01-15T09:00:36.491584Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.5)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\nRequirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (0.18.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\nRequirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.5)\nRequirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\nRequirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.8.0+cu126)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.10.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.1rc0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\nRequirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\nRequirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\nRequirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.4.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.6.2)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"outputs\",\n    per_device_train_batch_size=2,\n    per_device_eval_batch_size=2,\n    gradient_accumulation_steps=2,\n    learning_rate=2e-4,\n    num_train_epochs=3,\n    logging_steps=10,\n    save_strategy=\"epoch\",\n    fp16=True,\n    bf16=False,\n    optim=\"adamw_torch\",\n    report_to=\"none\",\n    run_name=\"qwen-qlora-go\",\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T09:00:36.493718Z","iopub.execute_input":"2026-01-15T09:00:36.494010Z","iopub.status.idle":"2026-01-15T09:00:36.529517Z","shell.execute_reply.started":"2026-01-15T09:00:36.493953Z","shell.execute_reply":"2026-01-15T09:00:36.528661Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"from transformers import DataCollatorWithPadding\nimport torch\n\nclass MinimalCausalLMCollator(DataCollatorWithPadding):\n    def __call__(self, features):\n        labels = [f.pop(\"labels\") for f in features]\n\n        batch = super().__call__(features)\n\n        max_len = batch[\"input_ids\"].size(1)\n\n        padded_labels = []\n        for l in labels:\n            padded_labels.append(l + [-100] * (max_len - len(l)))\n\n        batch[\"labels\"] = torch.tensor(padded_labels, dtype=torch.long)\n        return batch\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T09:00:36.530695Z","iopub.execute_input":"2026-01-15T09:00:36.531056Z","iopub.status.idle":"2026-01-15T09:00:41.891916Z","shell.execute_reply.started":"2026-01-15T09:00:36.530997Z","shell.execute_reply":"2026-01-15T09:00:41.891134Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"data_collator = MinimalCausalLMCollator(tokenizer=tokenizer)\n\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_ds[\"train\"],\n    eval_dataset=tokenized_ds[\"validation\"],\n    data_collator=data_collator,\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T09:00:41.893056Z","iopub.execute_input":"2026-01-15T09:00:41.893356Z","iopub.status.idle":"2026-01-15T09:00:41.919697Z","shell.execute_reply.started":"2026-01-15T09:00:41.893324Z","shell.execute_reply":"2026-01-15T09:00:41.919167Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T09:00:41.920584Z","iopub.execute_input":"2026-01-15T09:00:41.920887Z","iopub.status.idle":"2026-01-15T09:17:56.913942Z","shell.execute_reply.started":"2026-01-15T09:00:41.920854Z","shell.execute_reply":"2026-01-15T09:17:56.913364Z"}},"outputs":[{"name":"stderr","text":"`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:929: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='666' max='666' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [666/666 17:11, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>2.263300</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>2.102900</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>1.992400</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>1.965800</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>1.996000</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>1.881300</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>1.953100</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>1.932100</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>1.902400</td>\n    </tr>\n    <tr>\n      <td>110</td>\n      <td>1.851700</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>1.940100</td>\n    </tr>\n    <tr>\n      <td>130</td>\n      <td>1.760400</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>1.865800</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>1.855300</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>1.838700</td>\n    </tr>\n    <tr>\n      <td>170</td>\n      <td>1.834500</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>1.798100</td>\n    </tr>\n    <tr>\n      <td>190</td>\n      <td>2.005900</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>1.809900</td>\n    </tr>\n    <tr>\n      <td>210</td>\n      <td>1.835700</td>\n    </tr>\n    <tr>\n      <td>220</td>\n      <td>1.688900</td>\n    </tr>\n    <tr>\n      <td>230</td>\n      <td>1.740900</td>\n    </tr>\n    <tr>\n      <td>240</td>\n      <td>1.973000</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>1.744600</td>\n    </tr>\n    <tr>\n      <td>260</td>\n      <td>1.891300</td>\n    </tr>\n    <tr>\n      <td>270</td>\n      <td>1.886600</td>\n    </tr>\n    <tr>\n      <td>280</td>\n      <td>1.873700</td>\n    </tr>\n    <tr>\n      <td>290</td>\n      <td>1.771800</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>1.902000</td>\n    </tr>\n    <tr>\n      <td>310</td>\n      <td>1.835500</td>\n    </tr>\n    <tr>\n      <td>320</td>\n      <td>1.765400</td>\n    </tr>\n    <tr>\n      <td>330</td>\n      <td>1.890200</td>\n    </tr>\n    <tr>\n      <td>340</td>\n      <td>1.841900</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>1.913600</td>\n    </tr>\n    <tr>\n      <td>360</td>\n      <td>1.794400</td>\n    </tr>\n    <tr>\n      <td>370</td>\n      <td>1.997500</td>\n    </tr>\n    <tr>\n      <td>380</td>\n      <td>1.938000</td>\n    </tr>\n    <tr>\n      <td>390</td>\n      <td>1.851200</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>1.947100</td>\n    </tr>\n    <tr>\n      <td>410</td>\n      <td>1.711300</td>\n    </tr>\n    <tr>\n      <td>420</td>\n      <td>1.802600</td>\n    </tr>\n    <tr>\n      <td>430</td>\n      <td>1.700000</td>\n    </tr>\n    <tr>\n      <td>440</td>\n      <td>1.845300</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>1.880100</td>\n    </tr>\n    <tr>\n      <td>460</td>\n      <td>1.791600</td>\n    </tr>\n    <tr>\n      <td>470</td>\n      <td>1.755600</td>\n    </tr>\n    <tr>\n      <td>480</td>\n      <td>1.677200</td>\n    </tr>\n    <tr>\n      <td>490</td>\n      <td>1.850000</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>1.870100</td>\n    </tr>\n    <tr>\n      <td>510</td>\n      <td>1.899600</td>\n    </tr>\n    <tr>\n      <td>520</td>\n      <td>1.789600</td>\n    </tr>\n    <tr>\n      <td>530</td>\n      <td>1.936400</td>\n    </tr>\n    <tr>\n      <td>540</td>\n      <td>1.772100</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>1.751600</td>\n    </tr>\n    <tr>\n      <td>560</td>\n      <td>1.882900</td>\n    </tr>\n    <tr>\n      <td>570</td>\n      <td>1.961400</td>\n    </tr>\n    <tr>\n      <td>580</td>\n      <td>1.786300</td>\n    </tr>\n    <tr>\n      <td>590</td>\n      <td>1.820800</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>1.772400</td>\n    </tr>\n    <tr>\n      <td>610</td>\n      <td>1.792900</td>\n    </tr>\n    <tr>\n      <td>620</td>\n      <td>1.929400</td>\n    </tr>\n    <tr>\n      <td>630</td>\n      <td>1.584300</td>\n    </tr>\n    <tr>\n      <td>640</td>\n      <td>1.800500</td>\n    </tr>\n    <tr>\n      <td>650</td>\n      <td>1.704400</td>\n    </tr>\n    <tr>\n      <td>660</td>\n      <td>1.839100</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:929: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:929: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=666, training_loss=1.8589520568962212, metrics={'train_runtime': 1034.4592, 'train_samples_per_second': 2.567, 'train_steps_per_second': 0.644, 'total_flos': 8597392409825280.0, 'train_loss': 1.8589520568962212, 'epoch': 3.0})"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"model.save_pretrained(ADAPTER_DIR)\ntokenizer.save_pretrained(ADAPTER_DIR)\n\nprint(f\"Adapter saved to {ADAPTER_DIR}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T09:17:56.914939Z","iopub.execute_input":"2026-01-15T09:17:56.915227Z","iopub.status.idle":"2026-01-15T09:17:57.301633Z","shell.execute_reply.started":"2026-01-15T09:17:56.915202Z","shell.execute_reply":"2026-01-15T09:17:57.300493Z"}},"outputs":[{"name":"stdout","text":"Adapter saved to ./adapters\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"!zip -r adaptermodel.zip ./adapters","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T09:17:57.302846Z","iopub.execute_input":"2026-01-15T09:17:57.303220Z","iopub.status.idle":"2026-01-15T09:17:58.741313Z","shell.execute_reply.started":"2026-01-15T09:17:57.303189Z","shell.execute_reply":"2026-01-15T09:17:58.740366Z"}},"outputs":[{"name":"stdout","text":"  adding: adapters/ (stored 0%)\n  adding: adapters/added_tokens.json (deflated 67%)\n  adding: adapters/adapter_config.json (deflated 57%)\n  adding: adapters/special_tokens_map.json (deflated 69%)\n  adding: adapters/tokenizer_config.json (deflated 89%)\n  adding: adapters/vocab.json","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":" (deflated 61%)\n  adding: adapters/adapter_model.safetensors (deflated 8%)\n  adding: adapters/merges.txt (deflated 57%)\n  adding: adapters/chat_template.jinja (deflated 71%)\n  adding: adapters/README.md (deflated 65%)\n  adding: adapters/tokenizer.json (deflated 81%)\n","output_type":"stream"}],"execution_count":17}]}